{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n",
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "from typing import Optional, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from collections import namedtuple\n",
    "print(np.__version__)\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "import wandb\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "# Set precision to 3 decimal places\n",
    "np.set_printoptions(precision=3, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, train the model across a small range of maze sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration using OmegaConf\n",
    "cfg = OmegaConf.create({\n",
    "    \"name\": \"maze_4to100_curriculum\",\n",
    "    \"maze\": {\n",
    "        \"width\": {\"min\": 4, \"max\": 100},\n",
    "        \"height\": {\"min\": 4, \"max\": 100},\n",
    "        \"cell_occupancy_prob\": {\"min\": 0, \"max\": 0.3},\n",
    "        \"max_steps\": \"L1SourceTarget\", # Use this to set the max steps to the L1 distance between source and target * 2\n",
    "        # To set paramters to constant values, use a float\n",
    "        # \"width\": 4,\n",
    "        # \"height\": 4,\n",
    "        # \"cell_occupancy_prob\": 0,\n",
    "        # \"max_steps\": 5, \n",
    "    },\n",
    "    \"search\": {\n",
    "        # MCTS configuration\n",
    "        \"num_simulations\": 50,\n",
    "        \"c_puct\": 2,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"num_resBlocks\": 4,\n",
    "        \"num_filters\": 64,\n",
    "    },\n",
    "    \"learn\": {\n",
    "        \"num_learn_iters\": 100,\n",
    "        \"num_self_play_iters\": 500,\n",
    "        \"num_parallel_games\": 250,\n",
    "        \"num_train_epochs\": 4,\n",
    "        \"train_batch_size\": 64,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"save_every\": 30,\n",
    "        \"use_wandb\": True,\n",
    "        # \"load_checkpoint\": \"maze_4to10_rtg_model_99\",\n",
    "        \"use_curriculum\": True,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maze:\n",
    "    \"\"\"2D Gridworld Maze Game\n",
    "    \"\"\"\n",
    "\n",
    "    # Note that the reward stored in the state is unnormalized\n",
    "    State = namedtuple('State', ['x', 'y', 'steps_left', 'reward'])\n",
    "\n",
    "    TARGET_REWARD = 100\n",
    "    MOVE_REWARD = -1\n",
    "    TIMEOUT_REWARD = -50\n",
    "\n",
    "    def __init__(self, width: int, height: int, cell_occupancy_prob: float = 0.3,seed: Optional[int] = None):\n",
    "        assert 0 <= cell_occupancy_prob < 1, \"Cell occupancy probability must be in the range [0, 1)\"\n",
    "        assert width > 2 and height > 2, \"Width and height must be greater than 2\"\n",
    "\n",
    "        self.width = int(width)\n",
    "        self.height = int(height)\n",
    "        self.seed = seed\n",
    "        self.cell_occupancy_prob = cell_occupancy_prob\n",
    "        self.generate_map()\n",
    "\n",
    "        # self.action_size = 5  # Up, Down, Left, Right, Stay\n",
    "        self.action_size = 4\n",
    "        self.observation_width = 5 # 5x5 observation window centered at the agent\n",
    "\n",
    "        # Max steps configuration\n",
    "        # Option 1: Set the max steps to be the width * height\n",
    "        # self.max_steps=width*height\n",
    "        if cfg.maze.max_steps == \"L1SourceTarget\":\n",
    "            # Option 2: Set the max steps to be 2 * the L1 distance between source and target\n",
    "            self.max_steps = 2 * (abs(self.source[0] - self.target[0]) + abs(self.source[1] - self.target[1]))\n",
    "        elif type(cfg.maze.max_steps) == int:\n",
    "            # Option 3: Manually set the max steps\n",
    "            self.max_steps = cfg.maze.max_steps\n",
    "\n",
    "    @classmethod\n",
    "    def generate_maze_params(cls, num_mazes:int, maze_cfg, seed: Optional[int]=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        maze_params = []\n",
    "        for param_name in ['width', 'height', 'cell_occupancy_prob']:\n",
    "            param = getattr(maze_cfg, param_name)\n",
    "            if isinstance(param, (float, int)):\n",
    "                values = np.full(num_mazes, param)\n",
    "            elif isinstance(param, dict) or isinstance(param, DictConfig) and 'min' in param and 'max' in param:\n",
    "                min_val, max_val = param['min'], param['max']\n",
    "                if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                    # Assumes that if the min and max are integers we want all integers\n",
    "                    values = np.random.randint(min_val, max_val + 1, size=num_mazes)\n",
    "                else:\n",
    "                    values = np.random.uniform(min_val, max_val, size=num_mazes)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid parameter configuration: {param}\")\n",
    "            maze_params.append(values)\n",
    "\n",
    "        # Combine into a single n x 3 array\n",
    "        maze_params = np.column_stack(maze_params)\n",
    "        return maze_params\n",
    "\n",
    "\n",
    "    def get_initial_state(self) -> State:\n",
    "        return Maze.State(self.source[0], self.source[1], self.max_steps, 0)\n",
    "    \n",
    "    def get_next_state(self, state: State, action):\n",
    "        dx, dy = self.action_to_delta(action)\n",
    "        # Additional reward is -1 for each x or y coordinate moved.\n",
    "        dr = (abs(dx) + abs(dy)) * Maze.MOVE_REWARD\n",
    "        if (state.x + dx, state.y + dy) == self.target:\n",
    "            dr += Maze.TARGET_REWARD\n",
    "        elif state.steps_left == 1:\n",
    "            dr += Maze.TIMEOUT_REWARD\n",
    "        return Maze.State(state.x + dx, state.y + dy, state.steps_left - 1, state.reward + dr)\n",
    "    \n",
    "    def get_encoded_observation(self, state: State):\n",
    "        # Get the observation window centered at the agent\n",
    "        # Assumes width is odd\n",
    "        half_width = self.observation_width // 2\n",
    "\n",
    "        # Pad the maze with obstacles (1s) to handle boundaries\n",
    "        padded_maze = np.pad(self.map, pad_width=half_width, mode='constant', constant_values=1)\n",
    "\n",
    "        # Adjust the agent's position due to padding\n",
    "        x_padded = state.x + half_width\n",
    "        y_padded = state.y + half_width\n",
    "\n",
    "        # Plane 0: Obstacles\n",
    "        # Extract the observation window where obstacle is 1 and free space is 0\n",
    "        plane_obstacles = padded_maze[\n",
    "            x_padded - half_width : x_padded + half_width + 1,\n",
    "            y_padded - half_width : y_padded + half_width + 1\n",
    "        ]\n",
    "\n",
    "        # Make sure that any number that is not 1 is 0\n",
    "        plane_obstacles[plane_obstacles != 1] = 0\n",
    "        return np.stack([plane_obstacles], axis=0)\n",
    "\n",
    "\n",
    "    def get_normalized_agent_position(self, state: State):\n",
    "        # Normalize the positions\n",
    "        return (state.x / self.width, state.y / self.height)\n",
    "    \n",
    "    def get_normalized_target_position(self):\n",
    "        return (self.target[0] / self.width, self.target[1] / self.height)\n",
    "    \n",
    "    def get_normalized_steps_left(self, state: State):\n",
    "        return state.steps_left / self.max_steps\n",
    "    \n",
    "    def get_normalized_distances(self):\n",
    "        # Returns the normalized distances in the x and y directions that can be travelled by the agent in 50% of the max steps\n",
    "        scaling_factor = 0.5\n",
    "\n",
    "        return (self.max_steps * scaling_factor / self.width, self.max_steps * scaling_factor / self.height)\n",
    "    \n",
    "    def get_encoded_scalar_features(self, state: State):\n",
    "        return (\n",
    "            *self.get_normalized_agent_position(state),\n",
    "            *self.get_normalized_target_position(),\n",
    "            self.get_normalized_steps_left(state),\n",
    "            *self.get_normalized_distances()\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_valid_actions(self, state: State):\n",
    "        valid_moves = []\n",
    "        for action in range(self.action_size):\n",
    "            dx, dy = self.action_to_delta(action)\n",
    "            nx, ny = state.x + dx, state.y + dy\n",
    "            if self.map[nx, ny] != 1:\n",
    "                valid_moves.append(action)\n",
    "        return valid_moves\n",
    "    \n",
    "    def get_value_and_terminated(self, state: State):\n",
    "        \"\"\"Returns the unnormalized reward and whether the episode is terminated\"\"\"\n",
    "        if (state.x, state.y) == self.target or state.steps_left == 0:\n",
    "            return state.reward, True\n",
    "        return state.reward, False\n",
    "    \n",
    "    def normalize_reward(self, reward):\n",
    "        # Normalize the reward between -1 and 1\n",
    "        max_reward = Maze.TARGET_REWARD\n",
    "        min_reward = Maze.TIMEOUT_REWARD + Maze.MOVE_REWARD * self.max_steps\n",
    "        return 2 * ((reward - min_reward) / (max_reward - min_reward)) - 1\n",
    "    \n",
    "    def unnormalize_reward(self, normalized_reward):\n",
    "        # Unnormalize the reward between -1 and 1\n",
    "        max_reward = Maze.TARGET_REWARD\n",
    "        min_reward = Maze.TIMEOUT_REWARD + Maze.MOVE_REWARD * self.max_steps\n",
    "        return 0.5 * (normalized_reward + 1) * (max_reward - min_reward) + min_reward\n",
    "    \n",
    "    def action_to_delta(self, action):\n",
    "        # action_to_delta = [(0, 1), (0, -1), (-1, 0), (1, 0), (0, 0)]  # Down, Up, Left, Right, Stay\n",
    "        action_to_delta = [(0, 1), (0, -1), (-1, 0), (1, 0)] \n",
    "        return action_to_delta[action]\n",
    "    \n",
    "    def action_to_string(self, action):\n",
    "        action_to_string = ['Down', 'Up', 'Left', 'Right', 'Stay']\n",
    "        return action_to_string[action]\n",
    "    \n",
    "    def generate_map(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            map = np.random.choice([0, 1], size=(self.width, self.height), p=[1-self.cell_occupancy_prob, self.cell_occupancy_prob])\n",
    "            # Make the boundaries of the maze walls\n",
    "            map[0, :] = 1\n",
    "            map[-1, :] = 1\n",
    "            map[:, 0] = 1\n",
    "            map[:, -1] = 1\n",
    "\n",
    "            # Randomly select two unique non-border positions for the source and target\n",
    "            while True:\n",
    "                # Generate two random positions within the non-border range\n",
    "                source = (np.random.randint(1, self.width - 1), np.random.randint(1, self.height - 1))\n",
    "                target = (np.random.randint(1, self.width - 1), np.random.randint(1, self.height - 1))\n",
    "                \n",
    "                # Ensure the positions are unique\n",
    "                if source != target:\n",
    "                    break\n",
    "            \n",
    "            # Make sure the source and target do not have obstacles\n",
    "            map[source] = 2\n",
    "            map[target] = 3\n",
    "\n",
    "            self.source = source\n",
    "            self.target = target\n",
    "\n",
    "            self.map = map\n",
    "            astar = AStar(self)\n",
    "            success, self.shortest_path = astar.solve()\n",
    "            if success:\n",
    "                break\n",
    "            if count % 20 == 0:\n",
    "                print(f\"Unsolvable maze {count}. Regenerating...\")\n",
    "\n",
    "    def visualize_path(self, path=None):\n",
    "        if path is None:\n",
    "            path = self.shortest_path\n",
    "        map = self.map.copy()\n",
    "        truncated_path = path[1:-1]  # Exclude source and target\n",
    "        for pos in truncated_path:\n",
    "            map[pos] = 4\n",
    "        self.visualize_state(map)\n",
    "\n",
    "    def visualize_state(self, map: Optional[np.ndarray] = None):\n",
    "        if map is None:\n",
    "            map = self.map\n",
    "        # Define colors for each type of cell\n",
    "        cmap = mcolors.ListedColormap(['white', 'black', 'red', 'green', 'cyan'])\n",
    "        \n",
    "        # Plot the maze using imshow\n",
    "        plt.imshow(map.T, cmap=cmap, vmin=0, vmax=4)\n",
    "        # plt.axis('off')  # Hide axes\n",
    "        plt.show()\n",
    "\n",
    "class AStar:\n",
    "    def __init__(self, maze: Maze):\n",
    "        self.maze = maze\n",
    "        self.start = maze.source\n",
    "        self.goal = maze.target\n",
    "        self.height, self.width = maze.height, maze.width\n",
    "\n",
    "    def heuristic(self, a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "        # Manhattan distance\n",
    "        return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "    def successors(self, pos: Tuple[int, int]) -> List[Tuple[int, int]]:\n",
    "        x, y = pos\n",
    "        successors = []\n",
    "        directions = [(0, 1),(0, -1), (-1, 0), (1, 0)]  # Down, Up, Left, Right\n",
    "        for dx, dy in directions:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if self.maze.map[nx, ny] != 1:\n",
    "                successors.append((nx, ny))\n",
    "        return successors\n",
    "\n",
    "    def solve(self) -> bool:\n",
    "        open = []\n",
    "        heapq.heappush(open, (0, self.start))\n",
    "        came_from = {}\n",
    "        g_score = {self.start: 0}\n",
    "\n",
    "        while open:\n",
    "            _, current = heapq.heappop(open)\n",
    "            \n",
    "            if current == self.goal:\n",
    "                path = [current]\n",
    "                while current in came_from:\n",
    "                    current = came_from[current]\n",
    "                    path.append(current)\n",
    "                path.reverse()\n",
    "                return True, path  # Maze is solvable\n",
    "\n",
    "            for successor in self.successors(current):\n",
    "                tentative_g_score = g_score[current] + 1\n",
    "                if successor not in g_score or tentative_g_score < g_score[successor]:\n",
    "                    came_from[successor] = current\n",
    "                    g_score[successor] = tentative_g_score\n",
    "                    f_score = tentative_g_score + self.heuristic(successor, self.goal)\n",
    "                    heapq.heappush(open, (f_score, successor))\n",
    "\n",
    "        return False, []  # Maze is not solvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maze = Maze(10, 4, cell_occupancy_prob=0.3)\n",
    "maze.visualize_state()\n",
    "maze.max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78.   , 87.   ,  0.123],\n",
       "       [50.   , 23.   ,  0.011],\n",
       "       [72.   , 93.   ,  0.075],\n",
       "       [91.   , 70.   ,  0.288],\n",
       "       [69.   , 91.   ,  0.148],\n",
       "       [80.   , 53.   ,  0.193],\n",
       "       [16.   , 55.   ,  0.033],\n",
       "       [17.   , 55.   ,  0.015],\n",
       "       [43.   , 67.   ,  0.1  ],\n",
       "       [85.   , 51.   ,  0.15 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Maze.generate_maze_params(num_mazes=10, maze_cfg=cfg.maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_resBlocks, num_filters, device):\n",
    "        super().__init__()\n",
    "\n",
    "        OBSERVATION_WIDTH = 5\n",
    "        ACTION_SIZE = 4\n",
    "\n",
    "        SCALAR_FEATURES_SIZE = 7  # see Maze.get_encoded_scalar_features\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        # Initial convolutional block\n",
    "        # The single input channel is for the observation where obstacles are 1 and free space is 0\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=num_filters),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Residual blocks\n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_filters) for _ in range(num_resBlocks)]\n",
    "        )\n",
    "\n",
    "        # Policy head convolutional part that gets flattened\n",
    "        self.policyHead_conv = nn.Sequential(\n",
    "            nn.Conv2d(num_filters, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Compute the size after flattening\n",
    "        policy_conv_output_size = 32 * OBSERVATION_WIDTH ** 2\n",
    "\n",
    "        # Policy head fully connected part\n",
    "        self.policyHead_flat = nn.Sequential(\n",
    "            nn.Linear(policy_conv_output_size + SCALAR_FEATURES_SIZE, 256),  # Adding scalar features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, ACTION_SIZE),\n",
    "        )\n",
    "\n",
    "        # Value head convolutional part\n",
    "        self.valueHead_conv = nn.Sequential(\n",
    "            nn.Conv2d(num_filters, 3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Compute the size after flattening\n",
    "        value_conv_output_size = 3 * OBSERVATION_WIDTH ** 2\n",
    "\n",
    "        # Value head fully connected part\n",
    "        self.valueHead_flat = nn.Sequential(\n",
    "            nn.Linear(value_conv_output_size + SCALAR_FEATURES_SIZE, 256), # Adding scalar features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Tanh() # Value is between -1 and 1\n",
    "        )\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x, scalar_features):\n",
    "        # x: Input tensor of shape (batch_size, 3, maze_height, maze_width)\n",
    "        # scalar_features: (batch_size, 7), normalized\n",
    "\n",
    "        # Initial convolutional block\n",
    "        x = self.startBlock(x)\n",
    "\n",
    "        # Residual blocks\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "\n",
    "        # Policy head\n",
    "        policy_x = self.policyHead_conv(x)  # Output is already flattened\n",
    "        # Concatenate positions\n",
    "        policy_x_concat = torch.cat([policy_x, scalar_features], dim=1)\n",
    "        policy = self.policyHead_flat(policy_x_concat)\n",
    "\n",
    "        # Value head\n",
    "        value_x = self.valueHead_conv(x)  # Output is already flattened\n",
    "        # Concatenate positions\n",
    "        value_x_concat = torch.cat([value_x, scalar_features], dim=1)\n",
    "        value = self.valueHead_flat(value_x_concat)\n",
    "\n",
    "        return policy, value\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Search node in the MCTS tree\"\"\"\n",
    "    def __init__(self, state, valid_actions, parent=None, last_action=None, prior_prob=0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.last_action = last_action\n",
    "        self.valid_actions = valid_actions\n",
    "        self.prior_prob = prior_prob\n",
    "\n",
    "        # Initialize attributes\n",
    "        self.is_leaf = True\n",
    "        self.children = []\n",
    "        self.visit_count = 0\n",
    "        self.value_sum = 0\n",
    "\n",
    "class GameEpisode:\n",
    "    \"\"\"Stateful episode of a game\"\"\"\n",
    "    def __init__(self, game: Maze):\n",
    "        self.game = game\n",
    "        self.state: Maze.State = game.get_initial_state()\n",
    "        self.memory = []\n",
    "        self.reward_history = []\n",
    "        self.root: Optional[Node] = Node(self.state, self.game.get_valid_actions(self.state))\n",
    "        self.node: Optional[Node] = None\n",
    "    \n",
    "class AlphaMCTS:\n",
    "    def __init__(self, search_cfg, model: ResNet):\n",
    "        self.cfg = search_cfg\n",
    "        self.model = model\n",
    "    \n",
    "    def play_game(self, game: Maze, max_iters = 1000, verbose=True, visualize=True):\n",
    "        \"\"\"Play a single game\"\"\"\n",
    "        state = game.get_initial_state()\n",
    "        path = []\n",
    "        root = Node(state, game.get_valid_actions(state))\n",
    "        for i in range(max_iters):\n",
    "            action_probs = self.search(game, root=root)\n",
    "            path.append((state.x, state.y))\n",
    "            print(f\"Step {i+1}: {state}, action_probs: {action_probs}\")\n",
    "            # Sample action from the action probabilities\n",
    "            action = np.random.choice(game.action_size, p=action_probs)\n",
    "            # Take the action with the highest probability\n",
    "            # action = np.argmax(action_probs)\n",
    "            # if verbose:\n",
    "            #     print(f\"Step {i+1}: {state}, action_probs: {action_probs} action chosen: {self.game.action_to_string(action)}\")\n",
    "            for child in root.children:\n",
    "                if child.last_action == action:\n",
    "                    # Set the child as the new root to preserve the search tree\n",
    "                    root = child\n",
    "                    break\n",
    "            state = root.state\n",
    "            \n",
    "            value, is_terminal = game.get_value_and_terminated(state)\n",
    "\n",
    "            if is_terminal:\n",
    "                path.append((state.x, state.y))\n",
    "\n",
    "                if verbose:\n",
    "                    if (state.x, state.y) == game.target:\n",
    "                        print(f\"Reached target in {i+1} steps\")\n",
    "                    else:\n",
    "                        print(f\"Terminated due to timeout in {i+1} steps\")\n",
    "                if visualize:\n",
    "                    game.visualize_path(path)\n",
    "                \n",
    "                return path, value\n",
    "                \n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def search(self, game: Maze, state: Optional[Maze.State] = None, root: Optional[Node] = None) -> np.ndarray:\n",
    "        if root is None and state is not None:\n",
    "            root = Node(state, game.get_valid_actions(state))\n",
    "        elif state is None and root is None:\n",
    "            assert False, \"Either state or root must be provided\"\n",
    "\n",
    "        # Conduct num_simulations simulations\n",
    "        for i in range(self.cfg.num_simulations):\n",
    "            node = root\n",
    "            # Selection all the way down till a leaf node\n",
    "            while not node.is_leaf:\n",
    "                node = self.select(node, game)\n",
    "\n",
    "            # Evaluate the leaf node\n",
    "            value, is_terminal = game.get_value_and_terminated(node.state)\n",
    "\n",
    "            # If the leaf node is not a terminal node then expand it and evaluate it\n",
    "            if not is_terminal:\n",
    "                # Query the model for the policy and value\n",
    "                policy, value = self.query_model(state=node.state, game=game)\n",
    "                value = game.unnormalize_reward(value)\n",
    "                # Mask invalid actions\n",
    "                valid_policy = np.zeros_like(policy)\n",
    "                valid_policy[node.valid_actions] = policy[node.valid_actions]\n",
    "                valid_policy /= np.sum(valid_policy)\n",
    "\n",
    "                self.expand(node, policy=valid_policy, game=game)\n",
    "                \n",
    "            self.backpropagate(node, value)\n",
    "\n",
    "        \n",
    "        # Return the action probabilities after search\n",
    "        action_probs = np.zeros(game.action_size)\n",
    "        for child in root.children:\n",
    "            action_probs[child.last_action] = child.visit_count\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def batch_search(self, episodes: List[GameEpisode]):\n",
    "        \n",
    "        # Conduct num_simulations simulations\n",
    "        for i in range(self.cfg.num_simulations):\n",
    "            # Collect nodes for expansion and evaluation\n",
    "            for ep in episodes:\n",
    "                ep.node = None # Reset the node marked for expansion and evaluation for each episode\n",
    "                node = ep.root\n",
    "                # Selection all the way down till a leaf node\n",
    "                while not node.is_leaf:\n",
    "                    node = self.select(node, ep.game)\n",
    "\n",
    "                # Evaluate the leaf node\n",
    "                value, is_terminal = ep.game.get_value_and_terminated(node.state)\n",
    "\n",
    "                if is_terminal:\n",
    "                    self.backpropagate(node, value)\n",
    "                else:\n",
    "                    ep.node = node # Mark the leaf node for expansion and evaluation\n",
    "\n",
    "            # Batch query the model for the policy and value\n",
    "            expandable_episodes = [ep_idx for ep_idx, ep in enumerate(episodes) if ep.node is not None]\n",
    "\n",
    "            if len(expandable_episodes) > 0:\n",
    "                obs = np.stack([episodes[ep_idx].game.get_encoded_observation(episodes[ep_idx].node.state) for ep_idx in expandable_episodes])\n",
    "                scalar_features = np.stack([episodes[ep_idx].game.get_encoded_scalar_features(episodes[ep_idx].node.state) for ep_idx in expandable_episodes])\n",
    "                tensor_obs = torch.tensor(obs, dtype=torch.float32, device=self.model.device)\n",
    "                tensor_scalar_features = torch.tensor(scalar_features, dtype=torch.float32, device=self.model.device)\n",
    "                # Query the model for the policy and value\n",
    "                policy, value = self.model(\n",
    "                    tensor_obs, tensor_scalar_features\n",
    "                    )\n",
    "                \n",
    "                policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
    "                value = value.cpu().numpy()\n",
    "            \n",
    "            # Expand the nodes and backpropagate\n",
    "            for batch_idx, ep_idx in enumerate(expandable_episodes):\n",
    "                node = episodes[ep_idx].node\n",
    "                ep_policy, ep_value = policy[batch_idx], value[batch_idx].item()\n",
    "\n",
    "                valid_policy = np.zeros_like(ep_policy)\n",
    "                valid_policy[node.valid_actions] = ep_policy[node.valid_actions]\n",
    "                valid_policy /= np.sum(valid_policy)\n",
    "\n",
    "                ep_value = ep.game.unnormalize_reward(ep_value)\n",
    "                self.expand(node, policy=valid_policy, game=episodes[ep_idx].game)\n",
    "                self.backpropagate(node, ep_value)\n",
    "    \n",
    "    def query_model(self, state: Maze.State, game: Maze) -> Tuple[np.ndarray, float]:\n",
    "        tensor_obs = torch.tensor(game.get_encoded_observation(state), dtype=torch.float32, device=self.model.device).unsqueeze(0)\n",
    "        tensor_scalar_features = torch.tensor(game.get_encoded_scalar_features(state), dtype=torch.float32, device=self.model.device).unsqueeze(0)\n",
    "        # Query the model for the policy and value\n",
    "        policy, value = self.model(\n",
    "            tensor_obs, tensor_scalar_features\n",
    "            )\n",
    "        \n",
    "        value = value.item()\n",
    "        normalized_policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
    "        return normalized_policy, value\n",
    "\n",
    "    def select(self, node: Node, game: Maze) -> Node:\n",
    "        ucbs = [self.calc_ucb(node, child, game) for child in node.children]\n",
    "        return node.children[np.argmax(ucbs)]\n",
    "\n",
    "    def calc_ucb(self, node: Node, child: Node, game: Maze) -> float:\n",
    "        # Assumes normalized values for value_sum\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            # Q-value needs to be noramalized between -1 and 1 for this formula.\n",
    "            q_value = game.normalize_reward(child.value_sum / child.visit_count)\n",
    "\n",
    "        u_value = self.cfg.c_puct * child.prior_prob * np.sqrt(node.visit_count) / (1 + child.visit_count)\n",
    "        \n",
    "        return q_value + u_value\n",
    "\n",
    "    \n",
    "    def expand(self, node: Node, policy, game: Maze) -> None:\n",
    "        _, is_terminal = game.get_value_and_terminated(node.state)\n",
    "        assert not is_terminal, \"Cannot expand a terminal node\"\n",
    "        \n",
    "        for action, prior_prob in enumerate(policy):\n",
    "            if prior_prob > 0:\n",
    "                child_state = game.get_next_state(node.state, action)\n",
    "                child_node = Node(child_state,\n",
    "                                  game.get_valid_actions(child_state),\n",
    "                                  parent=node,\n",
    "                                  last_action=action,\n",
    "                                  prior_prob=prior_prob)\n",
    "                node.children.append(child_node)\n",
    "        \n",
    "        node.is_leaf = False\n",
    "\n",
    "    def backpropagate(self, node: Node, value: float) -> None:\n",
    "        \"\"\"Takes in unnormalized value\"\"\"\n",
    "        while node is not None:\n",
    "            node.visit_count += 1\n",
    "            node.value_sum += value\n",
    "            node = node.parent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "    def __init__(self, model: ResNet, optimizer, search_alg: AlphaMCTS, seed=None):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.search_alg = search_alg\n",
    "\n",
    "        self.cfg = cfg.learn\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        self.last_success_rate = None\n",
    "        self.last_maze_cfg = None\n",
    "        self.original_maze_cfg = cfg.maze\n",
    "    \n",
    "    def get_maze_cfg_from_curriculum(self):\n",
    "        if self.last_success_rate is None:\n",
    "            maze_cfg = copy.deepcopy(self.original_maze_cfg)\n",
    "            maze_cfg.width.max = 6\n",
    "            maze_cfg.height.max = 6\n",
    "            return maze_cfg\n",
    "\n",
    "        if self.last_success_rate >= 0.9:\n",
    "            # Increase the maze size\n",
    "            maze_cfg = copy.deepcopy(self.last_maze_cfg)\n",
    "            maze_cfg.width.max = min(self.last_maze_cfg.width.max + 2, self.original_maze_cfg.width.max)\n",
    "            maze_cfg.height.max = min(self.last_maze_cfg.height.max + 2, self.original_maze_cfg.height.max)\n",
    "        else:\n",
    "            # Keep the maze size the same\n",
    "            maze_cfg = self.last_maze_cfg\n",
    "        \n",
    "        return maze_cfg\n",
    "    \n",
    "    def self_play(self, maze_cfg):\n",
    "\n",
    "        maze_params = Maze.generate_maze_params(self.cfg.num_parallel_games, maze_cfg=maze_cfg)\n",
    "        episodes = [GameEpisode(Maze(*params)) for params in maze_params]\n",
    "        ret_mem = []\n",
    "        n_successes = 0\n",
    "        while len(episodes) > 0:\n",
    "            \n",
    "            self.search_alg.batch_search(episodes)\n",
    "\n",
    "            # Serially process the episodes\n",
    "            for i in range(len(episodes))[::-1]:\n",
    "                ep = episodes[i]\n",
    "\n",
    "                action_probs = np.zeros(ep.game.action_size)\n",
    "                for child in ep.root.children:\n",
    "                    action_probs[child.last_action] = child.visit_count\n",
    "                action_probs /= np.sum(action_probs)\n",
    "                ep.memory.append((ep.game.get_encoded_observation(ep.root.state), \n",
    "                                  ep.game.get_encoded_scalar_features(ep.root.state),\n",
    "                                  action_probs))\n",
    "                ep.reward_history.append(ep.root.state.reward)\n",
    "\n",
    "                action = np.random.choice(ep.game.action_size, p=action_probs)\n",
    "                for child in ep.root.children:\n",
    "                    if child.last_action == action:\n",
    "                        # Set the child as the new root to preserve the search tree\n",
    "                        ep.root = child\n",
    "                        break\n",
    "                ep.state = ep.root.state\n",
    "\n",
    "                final_reward, is_terminal = ep.game.get_value_and_terminated(ep.state)\n",
    "\n",
    "                if is_terminal:\n",
    "                    # Unroll the reward history and memory\n",
    "                    for mem, reward_to_go in zip(ep.memory, ep.reward_history):\n",
    "                        reward_to_go = final_reward - reward_to_go\n",
    "                        ret_mem.append((*mem, ep.game.normalize_reward(reward_to_go)))\n",
    "                    if (ep.state.x, ep.state.y) == ep.game.target:\n",
    "                        n_successes += 1\n",
    "                    del episodes[i]\n",
    "        \n",
    "        return ret_mem, n_successes\n",
    "        \n",
    "    def train(self, memory, iteration, epoch):\n",
    "        random.shuffle(memory)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batchIdx in range(0, len(memory), self.cfg.train_batch_size):\n",
    "            batch = memory[batchIdx:batchIdx + self.cfg.train_batch_size]\n",
    "            obs, scalar_features, policy_targets, value_targets = zip(*batch)\n",
    "\n",
    "            obs, scalar_features, policy_targets, value_targets = np.array(obs), np.array(scalar_features), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "            obs = torch.tensor(obs, dtype=torch.float32, device=self.model.device)\n",
    "            scalar_features = torch.tensor(scalar_features, dtype=torch.float32, device=self.model.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
    "            \n",
    "            policy_pred, value_pred = self.model(obs, scalar_features)\n",
    "            value_loss = F.mse_loss(value_pred, value_targets)\n",
    "            policy_loss = F.cross_entropy(policy_pred, policy_targets)\n",
    "            loss = value_loss + policy_loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.cfg.use_wandb:\n",
    "                # Log metrics for the current batch\n",
    "                wandb.log({\"batch_loss\": loss.item()})\n",
    "        \n",
    "        avg_loss = total_loss / (len(memory) // self.cfg.train_batch_size)\n",
    "        if self.cfg.use_wandb:\n",
    "            # Log average loss for the epoch\n",
    "            wandb.log({\"train_epoch_loss\": avg_loss, \"iteration\": iteration, \"epoch\": epoch})\n",
    "\n",
    "\n",
    "    def learn(self):\n",
    "        if self.cfg.use_wandb:\n",
    "            wandb.init(project=\"alpha-zero-discrete-maze\",\n",
    "                name=cfg.name,\n",
    "                config=OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True),\n",
    "                save_code=True)\n",
    "            \n",
    "            wandb.watch(self.model, log=\"all\", log_freq=10)  # Log model gradients and parameters\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        for iteration in range(self.cfg.num_learn_iters):\n",
    "            memory = []\n",
    "            successes = 0\n",
    "        \n",
    "            self.model.eval()\n",
    "\n",
    "            # Initialize all games and an episode for each game\n",
    "            if self.cfg.use_curriculum:\n",
    "                maze_cfg = self.get_maze_cfg_from_curriculum()\n",
    "                wandb.log({\"max_maze_width\": maze_cfg.width.max})\n",
    "                self.last_maze_cfg = maze_cfg\n",
    "            else:\n",
    "                maze_cfg = cfg.maze\n",
    "\n",
    "            for _ in trange(self.cfg.num_self_play_iters // self.cfg.num_parallel_games):\n",
    "                batch_episode_mems, num_episode_successes = self.self_play(maze_cfg)\n",
    "                successes += num_episode_successes\n",
    "                memory += batch_episode_mems\n",
    "\n",
    "            success_rate = successes / self.cfg.num_self_play_iters\n",
    "            self.last_success_rate = success_rate\n",
    "            if self.cfg.use_wandb:\n",
    "                # Log the success rate for self-play games\n",
    "                wandb.log({\"success_rate\": success_rate, \"iteration\": iteration, \"wall_time\": time.time() - start_time})\n",
    "                \n",
    "            self.model.train()\n",
    "            for epoch in trange(self.cfg.num_train_epochs):\n",
    "                self.train(memory, iteration, epoch)\n",
    "            \n",
    "            # Save if iter divides save_every or if it is the last iteration\n",
    "            if (iteration % self.cfg.save_every == 0 and iteration != 0) or iteration == self.cfg.num_learn_iters - 1:\n",
    "                torch.save(self.model.state_dict(), f\"checkpoints/{cfg.name}_model_{iteration}.pt\")\n",
    "                torch.save(self.optimizer.state_dict(), f\"checkpoints/{cfg.name}_optimizer_{iteration}.pt\")\n",
    "\n",
    "                if self.cfg.use_wandb:\n",
    "                    # Log model checkpoint to W&B\n",
    "                    wandb.save(f\"{cfg.name}_model_{iteration}.pt\")\n",
    "                    wandb.save(f\"{cfg.name}_optimizer_{iteration}.pt\")\n",
    "        if self.cfg.use_wandb:\n",
    "            wandb.finish()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshaoyuan\u001b[0m (\u001b[33mcontact_placement\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/shaoyuan/Documents/Software/AlphaZeroFromScratch/discrete_maze/wandb/run-20241114_204046-bvgmnk7h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/contact_placement/alpha-zero-discrete-maze/runs/bvgmnk7h' target=\"_blank\">maze_4to100_curriculum</a></strong> to <a href='https://wandb.ai/contact_placement/alpha-zero-discrete-maze' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/contact_placement/alpha-zero-discrete-maze' target=\"_blank\">https://wandb.ai/contact_placement/alpha-zero-discrete-maze</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/contact_placement/alpha-zero-discrete-maze/runs/bvgmnk7h' target=\"_blank\">https://wandb.ai/contact_placement/alpha-zero-discrete-maze/runs/bvgmnk7h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d411d2899304bbab48404a5fcf60767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5add17838f0c4ecea739559ca74c7bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569316fa13c14cada93b51dacaad1344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d115a5dc15e1444f82f9da863daecd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070767db124d43eabbf96a0cddee021d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056e528d068c48cd9c81f9e6133e7419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d43c66111f42118f630517c8195d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d106b877df43928553d6277c62c017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2224d21cc6024d8cbcab79d412134851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2812b0afb34dd0ab471979127af084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25732ba087354361b2ac289ec46843e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bd9ce664d04f00a832d836a9c12701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7146540f204c9995f1c3d1dc283f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5863eb295ee34da6bd43e5ba16ecdd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777da53da8cb457f9702dbd89f2c90c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a820676e49540d689be06e098a1667c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffadc12916d648be9e5f25fe26fb13c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de67b3dba3ed4432acc9f6d481320d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243ab09a8ba147d994d9d33e2c165457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c7544d8adb43968ad510d446baa118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64975a687aa545c58561baf5bc33ba31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb84ebc419741039e7f12c7dc5672a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7857c7fb94f6466298ab87ab26de069a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6cae2a8467241c7a34aab3e63266385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5afdfc9c6c48b898be7a7e609c35e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bbd2c65a3a4ec185dc00d4d77a0192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b5421d9919434b94539b4c51fa1c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70f63b4cdd84ba4a219aa137ee9e048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0284e16be24d3da48a4cb0449965a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca16938779854097b6bc9a6ea94cc489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68be761c43104a61b0efc2830891e17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a694068468b4d648e8fe2e121cc1eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958bb8cbda184fdaa6b08d029c24b105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb916329ccd410a84b1e420ab2ff187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69917baedb448c090365b9cf91a31cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76e662815a14ebb8b4df5ed983a3e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86d2451f19549509cc61cf009853a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de62a208adf4b66858fea9683e3382c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3090eca239b544509525f3ee3cb5803c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e589cb0093c4cce93fb9cc4249d5a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0845235254904c31940ad4336e29b066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d2518372024a748420045766c5c61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e6608478de42ba818874fb87563434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6700fb7517e548448e806de369f822eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945c96419c7b468ba45631a077c2b1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f889d749e345a79910a9d6635d8c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d420cb0fd7ea439b99cbc98c9664998d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e946cc9bcad1449782a91918ef0ef564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab1a98b9e36467b9d3fb08d6862d475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06186975f7114e8ba2b1b33f1cd30998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1141867ea244e694e147872c764b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b7d2d860f44abca4d85d4fff2c4ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c303713a40df4dfdac0fcd3ed17891c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e453c249d041a2b0944263343949d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4542a00ac74e46f491af8f0d0ddb215f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4372357ee29e4fddb093c080d0997e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4841e40e1f854c0094bbefdb072a9cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67ad3c1b76a44e2a75bb02512b8f0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd197f49bc0b47b1a5c3ddb920b83049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077749c796d84d7086a9fadcbd8b1bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9d7b029779454bb0541724cfdf4a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2531bc89244951a84efb1ec4d1cff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e195f1e21801465a80c9010111744536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24be3cad3ac94d68a1f62d72d423acf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd18ab693ef49a29b1b0f988c9f9758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08ca4d58b1345c4a72560ab7164a81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf367303f6341038843fcc3bbe363b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41300778dc740d8a6f8b412f4e3dacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4e4051c18c4e439c964a606bf3757c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbeb73cf7f9a491c8798ff9ac0f7af77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc066a2a2954a9abc1261755162ff31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b01a4f29458481cab7d398baf47dc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6607974492b047619bb68b4bff79c5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3926d91b60b41abb281ca998a1a9932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c346a95129a44b3be0254b9893768a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7bce6d7dd24a8c802d3bc76ba3c4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e178c22be8347d9b6461afb5fcf9d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3ad1a8190f4446a0f258643f91a1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69775d6bbc934115ab6db53530dd7f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167e13f0a6cb46b5b63293b76f3b56ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e52e4e33494c5ca62a7d35b2ff5dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71cf3a0bb0d41c8a6e325c3caa73906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d88690772b47e89cd3dd15c0765ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44de4504fd014b2db8d7fdd71c0797ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c56e7ab3334754aeddea8942e47e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436e1d3a6c094ef29903eef17c0fc675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450918752f0045f1a151ba603bbd85c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935322d85d7843fcbdb5fbdba5e9e90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767578699d2247c6aa81191946ee61cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfce869bc294433a3802bc42e03bfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a354f9c2d5514223889edca4a159e58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23791e8bbba546d9b7abb7bfd9ca4e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3083fa8662e43c28d33fb05cdf27c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05e281e903941218afed659f454fdcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638017ce483247a19a32df6feb7ad6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06c0ecde1164a2da6888ff0b8763665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18999b01bef541849368657ec7da05e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d462e4594d3b4cb69f02708002afe3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4c2859968a4792848cca55766400fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74af2a3db77f4917b674c172776dcb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dffb87e7384a14adc04dc441c9ae02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910ae21b093e40f5817a82fd60f37f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452d00093e884f3ba91837c641384623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c2c2fdcbd24e24adec927734b132a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4980cb9bd9485d8475551f0a36dec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3312134f1b594e4abb4fd76e514c83a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a049cb3bca4d469b22435d3eceddb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b616ccc2ceb14b63b2e40e830f884adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4facc0e2b4834ddba09f9a5b5ab97e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2db38d7cc44a859506e5b61bef6220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee90e269d6a495fbf7e0edacec52892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79174fbfd1fc46a99712f5bb75b7dad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce607afcddd14a63a5591ab268508ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6935956b4a49adbb0902501e5d48ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e883cecc520a4e6cb28ad941c99b0d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ee83803ece46e982844d45ae6d50d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e23f861aa1647aa8351f2456a29a16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792a4faf31a9463da3173d66058a2bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e42b2c528ff4a11bd22788434fa108e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4ab9e381c645089a0866f270b38b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116a83b48d6d4b54ba58f017eccd1aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5533d962104849698d6ce8ea188e3255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a177b31e6444f0943e9edec61be9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20825f9189284e0c8ea882b62acdbcc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5a87dc712d4e93b21b0e9e99cd2d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beeae99ca7b341a4bb8329e07ec4d291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2e1a77fe8142ac9fb31e0bcb016d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b19ea2c9cb54b80b9ac453129d59f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5d80e34f9a4b03a933d000f04a19b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38445838b95c4975bfc489d424c8b083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c4597525d147aea28cbc97a812e860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf397f35b91a413085f4a0edd04e0112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32baa7c298a7470284894ec059efe5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946f276ee9dc423cbf3462bc5d9811a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08966732908a423caef02aeeed8c8134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28173fe683b2419e9f8fcc120d1ec9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf0acc2263f45d0a386e45315647365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc84137974da485ea0949d44cae373f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ad65393042486fb2086a5baafae4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735cf9289f6f410b84fb4b6be226cb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49a05cac4f34e7b8a40a176baf7b6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48c8fdfaf89480ba5471d5f4ff771f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c661d9c1554a46a9ac06bf8ae4a6c1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4cb24ae89f47dfaa1de64af5897aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f0ae7902a045d399449f1c76be2ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ee759f75fa4ea0a922c98020062223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa0509b53914971913265979bf6efdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e580aa11be74011b3bb4feaddc74630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ac84a8664b47fea73aa478faa10886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe04b3833fbf46c2a3b71c69572d088f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8039e67eca464726bc064f3e102249b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2507f0c649b4e499451ce5073cfd460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df1c14fcf414bf69f0402a342b42a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b4db0b55fe4898af3f3afc51b563b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1092a2987924b1f8c08529341e7211d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f54dd48c984b13ba6c284aa8329725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1607bf55644445a2b8471bb1b02a393b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd09fbe8e58c4b26a5bb0dc9c72145ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5394e8cb073b4fc9b835d596fb6471ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af4a9f3b77b4f9983e31cbe84dc41e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd1bb1972714a3dbe397504bcdb1ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc76b9d228641cab934f66ed3e39020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1554eab19744492291b366785e3a59a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dff02b46284399937af47f23dbeea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2aa5d2a1114a269baf37b3c9215e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9545da54db2d4adfaa7cb49cd1767f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aec75d59f4944d59618ce2ff7dcf64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59a5611740e4c6faa4b796b24bdb068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d9361e695c4bb6a2584fcad8c859a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0474c72220d54bf391d2da337a0ec7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d50eb9347bb4ea59d26fdc04b7b174e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82ffaba65ce48e1bcd93ef3b1ae13c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78657e9b87c047fdad0a42f090f3c463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6a105bbd644c7293421df44dbc5873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7450769d654441a598897ec35f7ffec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707668f62d4745ec884785b26f018c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35c17ca7b634452a20493e3fe6f409c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1824de94e1f4a979e7d6f8ea2865db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c073abfc820a4c149bc52c9f3e423eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83277e2ac4c74951b28031b441a25788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4caf21bab0493ea0e899d0cb53dfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ee956bb040442781351a1b49b12ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8879a659f8a64157bae51d3dd6cce79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a65688a336045889f5bb1d35a7b7e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d784652a22a417ca8688969e9a4fef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60406e930bf4cedb202fd3453b82dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bfc9a49b3c405dbc49f5a9a9d721eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c85d0c5f7e4bec8cb6adb2c71dbfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008d3835cfe94af2b7d3720d5b51739c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4b083e5a8c4d548f4b7617ba063048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc1704fb65044cf993484f2a21f9c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8cf7b35a814b34b4ff913101252315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092cd76ef11e443492de8201c7f9e947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf953694111450faf9191a267d74666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c1fa9010e14377a930893a6837b350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec60d96af2fc46588cffe02cb26557ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e6b3f8af9648289edb35f9594fc25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e89206fe97482b8612e7ac6ecbba4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1a315cb65443ff8023b01aed4e8269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58048e4cf49a4e569011a074835904f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1f55b8497344e5830510e199bdbcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.214 MB of 0.214 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>█▆█▅▄▇▃▃▂▅▄▂▃▁▃▂▃▃▃▂▄▅▂▃▃▄▇▂▁▂▆▃▂▂▃▂▃▄▂▃</td></tr><tr><td>epoch</td><td>▆▁▆▃██▆▃▆▁▁▆▆▁▁▃▃▆█▃▁██▁██▆▁█▃█▃▆█▆▁▃▃▆█</td></tr><tr><td>iteration</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>max_maze_width</td><td>▁▁▁▁▁▁▁▂▃▃▃▄▄▅▅▆▆▇▇▇████████████████████</td></tr><tr><td>success_rate</td><td>▁▅▇██▇▆▇▇█▇█▇▇▆▇▇▆█▅▅▅▅▆▆▆▆▄▅▅▇▇▆▆▆▆▇▅▆▆</td></tr><tr><td>train_epoch_loss</td><td>▇██▆▄▆▂▃▃▃▂▁▂▂▁▂▂▂▁▃▂▃▃▂▃▄▂▃▂▂▁▂▂▂▃▂▁▂▁▃</td></tr><tr><td>wall_time</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.53641</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>iteration</td><td>99</td></tr><tr><td>max_maze_width</td><td>42</td></tr><tr><td>success_rate</td><td>0.864</td></tr><tr><td>train_epoch_loss</td><td>0.55301</td></tr><tr><td>wall_time</td><td>9253.08143</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">maze_4to100_curriculum</strong> at: <a href='https://wandb.ai/contact_placement/alpha-zero-discrete-maze/runs/bvgmnk7h' target=\"_blank\">https://wandb.ai/contact_placement/alpha-zero-discrete-maze/runs/bvgmnk7h</a><br/> View project at: <a href='https://wandb.ai/contact_placement/alpha-zero-discrete-maze' target=\"_blank\">https://wandb.ai/contact_placement/alpha-zero-discrete-maze</a><br/>Synced 4 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241114_204046-bvgmnk7h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNet(cfg.model.num_resBlocks, cfg.model.num_filters, device)\n",
    "if \"load_checkpoint\" in cfg.learn:\n",
    "    # Replace \"optimizer\" with \"model\"\n",
    "    model_filename = cfg.learn.load_checkpoint.replace(\"optimizer\", \"model\")\n",
    "    model.load_state_dict(torch.load(f\"checkpoints/{model_filename}.pt\"))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learn.lr, weight_decay=cfg.learn.weight_decay)\n",
    "if \"load_checkpoint\" in cfg.learn:\n",
    "    # Replace \"model\" with \"optimizer\"\n",
    "    model_filename = cfg.learn.load_checkpoint.replace(\"model\", \"optimizer\")\n",
    "    optimizer.load_state_dict(torch.load(f\"checkpoints/{model_filename}.pt\"))\n",
    "\n",
    "mcts = AlphaMCTS(search_cfg=cfg.search, model=model)\n",
    "\n",
    "alphaZero = AlphaZero(model, optimizer, mcts, seed=0)\n",
    "alphaZero.learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without GPU it took 4m 33s to run,\n",
    "With GPU it surprisingly took 5m 24s to run. Since our observation matrices are small I don't expect GPU support to make a huge difference. Perhaps it's also introducing some overhead?\n",
    "\n",
    "With parallelization of the self play (num parallel = 100) it took 1m 5s, (without wandb took 44s)\n",
    "(num parallel= 250) took 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_409461/2795563543.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"checkpoints/{cfg.name}_model_{cfg.learn.num_learn_iters - 1}.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: State(x=39, y=49, steps_left=116, reward=0), action_probs: [0. 0. 0. 1.]\n",
      "Step 2: State(x=40, y=49, steps_left=115, reward=-1), action_probs: [0. 0. 0. 1.]\n",
      "Step 3: State(x=41, y=49, steps_left=114, reward=-2), action_probs: [0.122 0.    0.    0.878]\n",
      "Step 4: State(x=42, y=49, steps_left=113, reward=-3), action_probs: [0.096 0.    0.    0.904]\n",
      "Step 5: State(x=43, y=49, steps_left=112, reward=-4), action_probs: [0. 0. 0. 1.]\n",
      "Step 6: State(x=44, y=49, steps_left=111, reward=-5), action_probs: [0.583 0.    0.    0.417]\n",
      "Step 7: State(x=44, y=50, steps_left=110, reward=-6), action_probs: [1. 0. 0. 0.]\n",
      "Step 8: State(x=44, y=51, steps_left=109, reward=-7), action_probs: [0.044 0.    0.    0.956]\n",
      "Step 9: State(x=45, y=51, steps_left=108, reward=-8), action_probs: [0. 0. 0. 1.]\n",
      "Step 10: State(x=46, y=51, steps_left=107, reward=-9), action_probs: [1. 0. 0. 0.]\n",
      "Step 11: State(x=46, y=52, steps_left=106, reward=-10), action_probs: [0.106 0.    0.    0.894]\n",
      "Step 12: State(x=47, y=52, steps_left=105, reward=-11), action_probs: [0. 0. 0. 1.]\n",
      "Step 13: State(x=48, y=52, steps_left=104, reward=-12), action_probs: [0. 0. 0. 1.]\n",
      "Step 14: State(x=49, y=52, steps_left=103, reward=-13), action_probs: [0.057 0.    0.    0.943]\n",
      "Step 15: State(x=50, y=52, steps_left=102, reward=-14), action_probs: [0.076 0.    0.    0.924]\n",
      "Step 16: State(x=51, y=52, steps_left=101, reward=-15), action_probs: [0.109 0.    0.    0.891]\n",
      "Step 17: State(x=52, y=52, steps_left=100, reward=-16), action_probs: [0.292 0.    0.    0.708]\n",
      "Step 18: State(x=53, y=52, steps_left=99, reward=-17), action_probs: [0.179 0.    0.    0.821]\n",
      "Step 19: State(x=54, y=52, steps_left=98, reward=-18), action_probs: [0.113 0.    0.    0.887]\n",
      "Step 20: State(x=55, y=52, steps_left=97, reward=-19), action_probs: [0. 0. 0. 1.]\n",
      "Step 21: State(x=56, y=52, steps_left=96, reward=-20), action_probs: [0.842 0.    0.    0.158]\n",
      "Step 22: State(x=56, y=53, steps_left=95, reward=-21), action_probs: [1. 0. 0. 0.]\n",
      "Step 23: State(x=56, y=54, steps_left=94, reward=-22), action_probs: [0.255 0.    0.    0.745]\n",
      "Step 24: State(x=57, y=54, steps_left=93, reward=-23), action_probs: [0.288 0.    0.    0.712]\n",
      "Step 25: State(x=57, y=55, steps_left=92, reward=-24), action_probs: [0.287 0.    0.    0.713]\n",
      "Step 26: State(x=57, y=56, steps_left=91, reward=-25), action_probs: [0.323 0.    0.    0.677]\n",
      "Step 27: State(x=57, y=57, steps_left=90, reward=-26), action_probs: [0.75 0.   0.   0.25]\n",
      "Step 28: State(x=57, y=58, steps_left=89, reward=-27), action_probs: [0.119 0.    0.    0.881]\n",
      "Step 29: State(x=58, y=58, steps_left=88, reward=-28), action_probs: [0.117 0.    0.    0.883]\n",
      "Step 30: State(x=59, y=58, steps_left=87, reward=-29), action_probs: [0.158 0.    0.    0.842]\n",
      "Step 31: State(x=60, y=58, steps_left=86, reward=-30), action_probs: [0.131 0.    0.    0.869]\n",
      "Step 32: State(x=61, y=58, steps_left=85, reward=-31), action_probs: [0. 0. 0. 1.]\n",
      "Step 33: State(x=62, y=58, steps_left=84, reward=-32), action_probs: [1. 0. 0. 0.]\n",
      "Step 34: State(x=62, y=59, steps_left=83, reward=-33), action_probs: [0.63 0.   0.   0.37]\n",
      "Step 35: State(x=62, y=60, steps_left=82, reward=-34), action_probs: [0.04 0.   0.   0.96]\n",
      "Step 36: State(x=63, y=60, steps_left=81, reward=-35), action_probs: [0.529 0.    0.    0.471]\n",
      "Step 37: State(x=64, y=60, steps_left=80, reward=-36), action_probs: [0.238 0.    0.    0.762]\n",
      "Step 38: State(x=65, y=60, steps_left=79, reward=-37), action_probs: [0.095 0.    0.    0.905]\n",
      "Step 39: State(x=65, y=61, steps_left=78, reward=-38), action_probs: [0.433 0.    0.    0.567]\n",
      "Step 40: State(x=65, y=62, steps_left=77, reward=-39), action_probs: [0.282 0.    0.    0.718]\n",
      "Step 41: State(x=66, y=62, steps_left=76, reward=-40), action_probs: [0.39 0.   0.   0.61]\n",
      "Step 42: State(x=67, y=62, steps_left=75, reward=-41), action_probs: [0.398 0.    0.    0.602]\n",
      "Step 43: State(x=68, y=62, steps_left=74, reward=-42), action_probs: [0.376 0.    0.    0.624]\n",
      "Step 44: State(x=68, y=63, steps_left=73, reward=-43), action_probs: [0.505 0.    0.    0.495]\n",
      "Step 45: State(x=69, y=63, steps_left=72, reward=-44), action_probs: [1. 0. 0. 0.]\n",
      "Step 46: State(x=69, y=64, steps_left=71, reward=-45), action_probs: [0.597 0.    0.    0.403]\n",
      "Step 47: State(x=69, y=65, steps_left=70, reward=-46), action_probs: [0.711 0.    0.    0.289]\n",
      "Step 48: State(x=70, y=65, steps_left=69, reward=-47), action_probs: [0.693 0.    0.    0.307]\n",
      "Step 49: State(x=70, y=66, steps_left=68, reward=-48), action_probs: [0.955 0.045 0.    0.   ]\n",
      "Step 50: State(x=70, y=67, steps_left=67, reward=-49), action_probs: [0.442 0.    0.    0.558]\n",
      "Step 51: State(x=71, y=67, steps_left=66, reward=-50), action_probs: [0.    0.    0.052 0.948]\n",
      "Step 52: State(x=72, y=67, steps_left=65, reward=-51), action_probs: [0.904 0.006 0.09  0.   ]\n",
      "Step 53: State(x=72, y=68, steps_left=64, reward=-52), action_probs: [0.656 0.    0.    0.344]\n",
      "Step 54: State(x=72, y=69, steps_left=63, reward=-53), action_probs: [0.274 0.086 0.    0.64 ]\n",
      "Step 55: State(x=73, y=69, steps_left=62, reward=-54), action_probs: [0.411 0.131 0.036 0.423]\n",
      "Step 56: State(x=74, y=69, steps_left=61, reward=-55), action_probs: [0.617 0.308 0.067 0.008]\n",
      "Step 57: State(x=74, y=70, steps_left=60, reward=-56), action_probs: [0.236 0.496 0.268 0.   ]\n",
      "Step 58: State(x=73, y=70, steps_left=59, reward=-57), action_probs: [0.305 0.11  0.    0.585]\n",
      "Step 59: State(x=74, y=70, steps_left=58, reward=-58), action_probs: [0.206 0.505 0.289 0.   ]\n",
      "Step 60: State(x=74, y=71, steps_left=57, reward=-59), action_probs: [0.101 0.71  0.174 0.014]\n",
      "Step 61: State(x=74, y=72, steps_left=56, reward=-60), action_probs: [0.    0.    0.214 0.786]\n",
      "Step 62: State(x=75, y=72, steps_left=55, reward=-61), action_probs: [0.602 0.301 0.097 0.   ]\n",
      "Step 63: State(x=75, y=73, steps_left=54, reward=-62), action_probs: [0.943 0.057 0.    0.   ]\n",
      "Step 64: State(x=75, y=74, steps_left=53, reward=-63), action_probs: [0.209 0.324 0.054 0.412]\n",
      "Step 65: State(x=75, y=73, steps_left=52, reward=-64), action_probs: [0.938 0.062 0.    0.   ]\n",
      "Step 66: State(x=75, y=72, steps_left=51, reward=-65), action_probs: [0.6   0.273 0.127 0.   ]\n",
      "Step 67: State(x=75, y=73, steps_left=50, reward=-66), action_probs: [0.927 0.073 0.    0.   ]\n",
      "Step 68: State(x=75, y=74, steps_left=49, reward=-67), action_probs: [0.224 0.304 0.056 0.416]\n",
      "Step 69: State(x=75, y=75, steps_left=48, reward=-68), action_probs: [0.143 0.26  0.104 0.494]\n",
      "Step 70: State(x=76, y=75, steps_left=47, reward=-69), action_probs: [0.092 0.632 0.069 0.207]\n",
      "Step 71: State(x=75, y=75, steps_left=46, reward=-70), action_probs: [0.127 0.291 0.091 0.491]\n",
      "Step 72: State(x=74, y=75, steps_left=45, reward=-71), action_probs: [0.111 0.426 0.13  0.333]\n",
      "Step 73: State(x=75, y=75, steps_left=44, reward=-72), action_probs: [0.164 0.299 0.119 0.418]\n",
      "Step 74: State(x=76, y=75, steps_left=43, reward=-73), action_probs: [0.091 0.662 0.065 0.182]\n",
      "Step 75: State(x=76, y=74, steps_left=42, reward=-74), action_probs: [0.26 0.   0.43 0.31]\n",
      "Step 76: State(x=77, y=74, steps_left=41, reward=-75), action_probs: [0.45 0.55 0.   0.  ]\n",
      "Step 77: State(x=77, y=75, steps_left=40, reward=-76), action_probs: [0.353 0.153 0.424 0.071]\n",
      "Step 78: State(x=76, y=75, steps_left=39, reward=-77), action_probs: [0.082 0.647 0.094 0.176]\n",
      "Step 79: State(x=76, y=74, steps_left=38, reward=-78), action_probs: [0.26  0.    0.462 0.279]\n",
      "Step 80: State(x=77, y=74, steps_left=37, reward=-79), action_probs: [0.5 0.5 0.  0. ]\n",
      "Step 81: State(x=77, y=75, steps_left=36, reward=-80), action_probs: [0.341 0.114 0.489 0.057]\n",
      "Step 82: State(x=76, y=75, steps_left=35, reward=-81), action_probs: [0.076 0.663 0.098 0.163]\n",
      "Step 83: State(x=76, y=74, steps_left=34, reward=-82), action_probs: [0.264 0.    0.491 0.245]\n",
      "Step 84: State(x=76, y=75, steps_left=33, reward=-83), action_probs: [0.077 0.641 0.115 0.167]\n",
      "Step 85: State(x=76, y=76, steps_left=32, reward=-84), action_probs: [0.127 0.109 0.273 0.491]\n",
      "Step 86: State(x=77, y=76, steps_left=31, reward=-85), action_probs: [0.303 0.447 0.25  0.   ]\n",
      "Step 87: State(x=77, y=77, steps_left=30, reward=-86), action_probs: [0.069 0.833 0.097 0.   ]\n",
      "Step 88: State(x=77, y=76, steps_left=29, reward=-87), action_probs: [0.275 0.431 0.294 0.   ]\n",
      "Step 89: State(x=77, y=77, steps_left=28, reward=-88), action_probs: [0.063 0.835 0.101 0.   ]\n",
      "Step 90: State(x=77, y=76, steps_left=27, reward=-89), action_probs: [0.296 0.426 0.278 0.   ]\n",
      "Step 91: State(x=77, y=77, steps_left=26, reward=-90), action_probs: [0.06  0.807 0.133 0.   ]\n",
      "Step 92: State(x=77, y=76, steps_left=25, reward=-91), action_probs: [0.293 0.457 0.25  0.   ]\n",
      "Step 93: State(x=77, y=75, steps_left=24, reward=-92), action_probs: [0.304 0.098 0.549 0.049]\n",
      "Step 94: State(x=77, y=76, steps_left=23, reward=-93), action_probs: [0.325 0.438 0.237 0.   ]\n",
      "Step 95: State(x=77, y=75, steps_left=22, reward=-94), action_probs: [0.286 0.107 0.548 0.06 ]\n",
      "Step 96: State(x=77, y=74, steps_left=21, reward=-95), action_probs: [0.483 0.517 0.    0.   ]\n",
      "Step 97: State(x=77, y=73, steps_left=20, reward=-96), action_probs: [0.494 0.165 0.    0.342]\n",
      "Step 98: State(x=78, y=73, steps_left=19, reward=-97), action_probs: [0.    0.092 0.882 0.026]\n",
      "Step 99: State(x=77, y=73, steps_left=18, reward=-98), action_probs: [0.5   0.259 0.    0.241]\n",
      "Step 100: State(x=77, y=72, steps_left=17, reward=-99), action_probs: [0.582 0.139 0.    0.278]\n",
      "Step 101: State(x=77, y=73, steps_left=16, reward=-100), action_probs: [0.453 0.274 0.    0.274]\n",
      "Step 102: State(x=77, y=74, steps_left=15, reward=-101), action_probs: [0.543 0.457 0.    0.   ]\n",
      "Step 103: State(x=77, y=73, steps_left=14, reward=-102), action_probs: [0.473 0.253 0.    0.275]\n",
      "Step 104: State(x=77, y=72, steps_left=13, reward=-103), action_probs: [0.597 0.139 0.    0.264]\n",
      "Step 105: State(x=77, y=73, steps_left=12, reward=-104), action_probs: [0.467 0.261 0.    0.272]\n",
      "Step 106: State(x=77, y=72, steps_left=11, reward=-105), action_probs: [0.589 0.151 0.    0.26 ]\n",
      "Step 107: State(x=77, y=71, steps_left=10, reward=-106), action_probs: [1. 0. 0. 0.]\n",
      "Step 108: State(x=77, y=72, steps_left=9, reward=-107), action_probs: [0.541 0.156 0.    0.303]\n",
      "Step 109: State(x=77, y=71, steps_left=8, reward=-108), action_probs: [1. 0. 0. 0.]\n",
      "Step 110: State(x=77, y=72, steps_left=7, reward=-109), action_probs: [0.452 0.2   0.    0.348]\n",
      "Step 111: State(x=77, y=73, steps_left=6, reward=-110), action_probs: [0.436 0.267 0.    0.297]\n",
      "Step 112: State(x=78, y=73, steps_left=5, reward=-111), action_probs: [0.    0.228 0.595 0.177]\n",
      "Step 113: State(x=78, y=72, steps_left=4, reward=-112), action_probs: [0.373 0.    0.343 0.284]\n",
      "Step 114: State(x=77, y=72, steps_left=3, reward=-113), action_probs: [0.389 0.208 0.    0.403]\n",
      "Step 115: State(x=78, y=72, steps_left=2, reward=-114), action_probs: [0.385 0.    0.308 0.308]\n",
      "Step 116: State(x=79, y=72, steps_left=1, reward=-115), action_probs: [0.219 0.493 0.288 0.   ]\n",
      "Terminated due to timeout in 116 steps\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(39, 49), (40, 49), (41, 49), (42, 49), (43, 49), (44, 49), (44, 50), (44, 51), (45, 51), (46, 51), (46, 52), (47, 52), (48, 52), (49, 52), (50, 52), (51, 52), (52, 52), (53, 52), (54, 52), (55, 52), (56, 52), (56, 53), (56, 54), (57, 54), (57, 55), (57, 56), (57, 57), (57, 58), (58, 58), (59, 58), (60, 58), (61, 58), (62, 58), (62, 59), (62, 60), (63, 60), (64, 60), (65, 60), (65, 61), (65, 62), (66, 62), (67, 62), (68, 62), (68, 63), (69, 63), (69, 64), (69, 65), (70, 65), (70, 66), (70, 67), (71, 67), (72, 67), (72, 68), (72, 69), (73, 69), (74, 69), (74, 70), (73, 70), (74, 70), (74, 71), (74, 72), (75, 72), (75, 73), (75, 74), (75, 73), (75, 72), (75, 73), (75, 74), (75, 75), (76, 75), (75, 75), (74, 75), (75, 75), (76, 75), (76, 74), (77, 74), (77, 75), (76, 75), (76, 74), (77, 74), (77, 75), (76, 75), (76, 74), (76, 75), (76, 76), (77, 76), (77, 77), (77, 76), (77, 77), (77, 76), (77, 77), (77, 76), (77, 75), (77, 76), (77, 75), (77, 74), (77, 73), (78, 73), (77, 73), (77, 72), (77, 73), (77, 74), (77, 73), (77, 72), (77, 73), (77, 72), (77, 71), (77, 72), (77, 71), (77, 72), (77, 73), (78, 73), (78, 72), (77, 72), (78, 72), (79, 72), (79, 71)], -166)\n",
      "Position: (1, 1), policy: [0.538 0.    0.    0.462], policy argmax:Down policy value: 0.6575314998626709\n",
      "search: [0.531 0.    0.    0.469], search argmax: Down\n",
      "Position: (1, 2), policy: [0.006 0.    0.    0.994], policy argmax:Right policy value: -0.9615854024887085\n",
      "search: [0. 0. 0. 1.], search argmax: Right\n",
      "Position: (1, 3), policy: [0.   0.01 0.   0.99], policy argmax:Right policy value: -0.9988717436790466\n",
      "search: [0. 1. 0. 0.], search argmax: Up\n",
      "Position: (1, 5), policy: [0. 0. 0. 1.], policy argmax:Right policy value: -0.09026403725147247\n",
      "search: [0. 0. 0. 1.], search argmax: Right\n",
      "Position: (1, 7), policy: [0.111 0.    0.    0.889], policy argmax:Right policy value: -0.9301568269729614\n",
      "search: [0.102 0.    0.    0.898], search argmax: Right\n",
      "Position: (1, 8), policy: [0. 0. 0. 1.], policy argmax:Right policy value: -0.9454125761985779\n",
      "search: [0. 0. 0. 1.], search argmax: Right\n",
      "Position: (1, 10), policy: [0.125 0.    0.    0.875], policy argmax:Right policy value: -0.8454585075378418\n",
      "search: [0.122 0.    0.    0.878], search argmax: Right\n",
      "Position: (1, 11), policy: [0. 0. 0. 1.], policy argmax:Right policy value: -0.9746581315994263\n",
      "search: [0. 0. 0. 1.], search argmax: Right\n",
      "Position: (1, 13), policy: [0.461 0.    0.005 0.535], policy argmax:Right policy value: -0.9975064396858215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_409461/161441880.py:95: RuntimeWarning: invalid value encountered in divide\n",
      "  valid_policy /= np.sum(valid_policy)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m     policy, final_reward \u001b[38;5;241m=\u001b[39m mcts\u001b[38;5;241m.\u001b[39mquery_model(state, game\u001b[38;5;241m=\u001b[39mmaze)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPosition: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, policy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpolicy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, policy argmax:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaze\u001b[38;5;241m.\u001b[39maction_to_string(np\u001b[38;5;241m.\u001b[39margmax(policy))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m policy value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m     search_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmcts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_probs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, search argmax: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaze\u001b[38;5;241m.\u001b[39maction_to_string(np\u001b[38;5;241m.\u001b[39margmax(search_probs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Actions: Down, Up, Left, Right\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Software/AlphaZeroFromScratch/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 82\u001b[0m, in \u001b[0;36mAlphaMCTS.search\u001b[0;34m(self, game, state, root)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Selection all the way down till a leaf node\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[0;32m---> 82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Evaluate the leaf node\u001b[39;00m\n\u001b[1;32m     85\u001b[0m value, is_terminal \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mget_value_and_terminated(node\u001b[38;5;241m.\u001b[39mstate)\n",
      "Cell \u001b[0;32mIn[7], line 173\u001b[0m, in \u001b[0;36mAlphaMCTS.select\u001b[0;34m(self, node, game)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, node: Node, game: Maze) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Node:\n\u001b[1;32m    172\u001b[0m     ucbs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_ucb(node, child, game) \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mchildren]\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mchildren[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mucbs\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/Documents/Software/AlphaZeroFromScratch/.venv/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:1359\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Software/AlphaZeroFromScratch/.venv/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/Documents/Software/AlphaZeroFromScratch/.venv/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:46\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# As this already tried the method, subok is maybe quite reasonable here\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# but this follows what was done before. TODO: revisit this.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m arr, \u001b[38;5;241m=\u001b[39m conv\u001b[38;5;241m.\u001b[39mas_arrays(subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 46\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(result, to_scalar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "# params = Maze.generate_maze_params(1, cfg)\n",
    "params = np.array([[100, 100, 0.2]])\n",
    "width, height, cell_occupancy_prob = params[0]\n",
    "width, height = int(width), int(height)\n",
    "maze = Maze(*params[0])\n",
    "\n",
    "maze.visualize_path()\n",
    "\n",
    "model = ResNet(cfg.model.num_resBlocks, cfg.model.num_filters, device)\n",
    "model.load_state_dict(torch.load(f\"checkpoints/{cfg.name}_model_{cfg.learn.num_learn_iters - 1}.pt\"))\n",
    "# model.load_state_dict(torch.load(f\"checkpoints/{cfg.name}_model_{100}.pt\"))\n",
    "# model.load_state_dict(torch.load(f\"checkpoints/maze_4x4_binaryreward_maxsteps2_wstepsleft_round3_model_13.pt\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "mcts = AlphaMCTS(search_cfg=cfg.search, model=model)\n",
    "\n",
    "print(mcts.play_game(game=maze))\n",
    "\n",
    "positions = [(x, y) for x in range(1, width-1) for y in range(1, height-1)]\n",
    "\n",
    "for pos in positions:\n",
    "    if pos == maze.target or maze.map[pos] == 1:\n",
    "        continue\n",
    "    state = Maze.State(*pos, 1, 0)\n",
    "    policy, final_reward = mcts.query_model(state, game=maze)\n",
    "    print(f\"Position: {pos}, policy: {policy}, policy argmax:{maze.action_to_string(np.argmax(policy))} policy value: {final_reward}\")\n",
    "    search_probs = mcts.search(game=maze, state=state)\n",
    "    print(f\"search: {search_probs}, search argmax: {maze.action_to_string(np.argmax(search_probs))}\")\n",
    "# Actions: Down, Up, Left, Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
